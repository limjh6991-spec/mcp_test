from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
from diffusers import StableDiffusionPipeline
import os
from datetime import datetime
from typing import Optional
import base64
from io import BytesIO
from PIL import Image
import requests
import asyncio

app = FastAPI(title="Stable Diffusion MCP (Cloud Enhanced)", version="2.0.0")

# ê¸€ë¡œë²Œ íŒŒì´í”„ë¼ì¸ ë³€ìˆ˜
pipeline = None

# í´ë¼ìš°ë“œ API ì„¤ì •
CLOUD_APIS = {
    'huggingface': {
        'enabled': True,
        'url': 'https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-2-1',
        'key': os.getenv('HF_API_KEY', 'hf_dummy')
    },
    'stability': {
        'enabled': bool(os.getenv('STABILITY_API_KEY')),
        'url': 'https://api.stability.ai/v1/generation/stable-diffusion-v1-6/text-to-image',
        'key': os.getenv('STABILITY_API_KEY')
    }
}

class ImageRequest(BaseModel):
    prompt: str
    resolution: str = '1024x1024'
    num_inference_steps: int = 20
    guidance_scale: float = 7.5
    seed: Optional[int] = None
    negative_prompt: Optional[str] = "blurry, low quality, distorted"

class ImageResponse(BaseModel):
    image_path: str
    image_base64: Optional[str] = None
    metadata: dict
    generation_time: float

def initialize_pipeline():
    """Stable Diffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
    global pipeline
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}, ë””ë°”ì´ìŠ¤: {device}")
        
        # Stable Diffusion 2.1 ëª¨ë¸ ë¡œë“œ
        model_id = "stabilityai/stable-diffusion-2-1"
        pipeline = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32
        )
        pipeline = pipeline.to(device)
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        if device == "cuda":
            pipeline.enable_attention_slicing()
            pipeline.enable_model_cpu_offload()
            
        print("Stable Diffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
    except Exception as e:
        print(f"íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
    success = initialize_pipeline()
    if not success:
        print("ê²½ê³ : Stable Diffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨. ë”ë¯¸ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

async def generate_with_huggingface(prompt: str, **kwargs):
    """HuggingFace Inference APIë¡œ ì´ë¯¸ì§€ ìƒì„± (ë¬´ë£Œ, ë¹ ë¦„)"""
    api_config = CLOUD_APIS['huggingface']
    headers = {"Authorization": f"Bearer {api_config['key']}"}
    payload = {"inputs": prompt}
    
    response = requests.post(api_config['url'], headers=headers, json=payload, timeout=30)
    
    if response.status_code == 200:
        return response.content
    else:
        raise Exception(f"HuggingFace API ì˜¤ë¥˜: {response.status_code}")

async def generate_with_stability(prompt: str, **kwargs):
    """Stability AI APIë¡œ ì´ë¯¸ì§€ ìƒì„± (ìœ ë£Œ, ìµœê³ í’ˆì§ˆ)"""
    api_config = CLOUD_APIS['stability']
    if not api_config['enabled']:
        raise Exception("Stability API í‚¤ ì—†ìŒ")
    
    headers = {
        "Authorization": f"Bearer {api_config['key']}",
        "Content-Type": "application/json"
    }
    
    width, height = map(int, kwargs.get('resolution', '1024x1024').split('x'))
    payload = {
        "text_prompts": [{"text": prompt}],
        "cfg_scale": kwargs.get('guidance_scale', 7.5),
        "steps": kwargs.get('num_inference_steps', 20),
        "width": width,
        "height": height
    }
    
    response = requests.post(api_config['url'], headers=headers, json=payload, timeout=60)
    
    if response.status_code == 200:
        data = response.json()
        return base64.b64decode(data['artifacts'][0]['base64'])
    else:
        raise Exception(f"Stability API ì˜¤ë¥˜: {response.status_code}")

@app.post('/create_robot_image', response_model=ImageResponse)
async def create_robot_image(request: ImageRequest):
    """
    í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 3D ë¡œë´‡ ì´ë¯¸ì§€ ìƒì„±
    ìš°ì„ ìˆœìœ„: HuggingFace API â†’ Stability AI â†’ ë¡œì»¬ â†’ ë”ë¯¸
    """
    start_time = datetime.now()
    
    try:
        # í•´ìƒë„ íŒŒì‹±
        width, height = map(int, request.resolution.split('x'))
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = "generated_images"
        os.makedirs(output_dir, exist_ok=True)
        
        image_data = None
        api_used = "none"
        
        # 1ìˆœìœ„: HuggingFace API (ë¬´ë£Œ, ë¹ ë¦„)
        try:
            print("ğŸš€ HuggingFace API ì‹œë„ ì¤‘...")
            image_data = await generate_with_huggingface(request.prompt, resolution=request.resolution)
            api_used = "huggingface"
            print("âœ… HuggingFace API ì„±ê³µ!")
        except Exception as e:
            print(f"âŒ HuggingFace API ì‹¤íŒ¨: {e}")
            
            # 2ìˆœìœ„: Stability AI API (ìœ ë£Œ, ê³ í’ˆì§ˆ)
            try:
                print("ğŸš€ Stability AI API ì‹œë„ ì¤‘...")
                image_data = await generate_with_stability(request.prompt, 
                                                         resolution=request.resolution,
                                                         guidance_scale=request.guidance_scale,
                                                         num_inference_steps=request.num_inference_steps)
                api_used = "stability"
                print("âœ… Stability AI API ì„±ê³µ!")
            except Exception as e2:
                print(f"âŒ Stability AI API ì‹¤íŒ¨: {e2}")
                
                # 3ìˆœìœ„: ë¡œì»¬ íŒŒì´í”„ë¼ì¸
                if pipeline is not None:
                    try:
                        print("ğŸš€ ë¡œì»¬ íŒŒì´í”„ë¼ì¸ ì‹œë„ ì¤‘...")
                        generator = torch.Generator().manual_seed(request.seed) if request.seed else None
                        
                        image = pipeline(
                            prompt=request.prompt,
                            negative_prompt=request.negative_prompt,
                            num_inference_steps=request.num_inference_steps,
                            guidance_scale=request.guidance_scale,
                            width=width,
                            height=height,
                            generator=generator
                        ).images[0]
                        
                        buffered = BytesIO()
                        image.save(buffered, format="PNG")
                        image_data = buffered.getvalue()
                        api_used = "local"
                        print("âœ… ë¡œì»¬ íŒŒì´í”„ë¼ì¸ ì„±ê³µ!")
                    except Exception as e3:
                        print(f"âŒ ë¡œì»¬ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e3}")
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        if image_data:
            image = Image.open(BytesIO(image_data))
        else:
            # 4ìˆœìœ„: ë”ë¯¸ ì´ë¯¸ì§€ (ìµœì¢… ë°±ì—…)
            print("ğŸ”§ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
            image = Image.new('RGB', (width, height), color='lightblue')
            buffered = BytesIO()
            image.save(buffered, format="PNG")
            image_data = buffered.getvalue()
            api_used = "dummy"
        
        # ì´ë¯¸ì§€ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        image_path = os.path.join(output_dir, f"robot_{api_used}_{timestamp}.png")
        
        image.save(image_path)
        
        # Base64 ì¸ì½”ë”© (ì„ íƒì )
        buffered = BytesIO()
        image.save(buffered, format="PNG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode()
        
        # ìƒì„± ì‹œê°„ ê³„ì‚°
        generation_time = (datetime.now() - start_time).total_seconds()
        
        # ë©”íƒ€ë°ì´í„°
        metadata = {
            "prompt": request.prompt,
            "resolution": request.resolution,
            "steps": request.num_inference_steps,
            "guidance_scale": request.guidance_scale,
            "seed": request.seed,
            "api_used": api_used,
            "device": "cuda" if torch.cuda.is_available() else "cpu",
            "model": f"{api_used}-api" if api_used != "local" else "stabilityai/stable-diffusion-2-1",
            "timestamp": datetime.now().isoformat()
        }
        
        return ImageResponse(
            image_path=os.path.abspath(image_path),
            image_base64=img_base64,
            metadata=metadata,
            generation_time=generation_time
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.get('/supported_resolutions')
async def get_supported_resolutions():
    """ì§€ì›ë˜ëŠ” í•´ìƒë„ ëª©ë¡ ë°˜í™˜"""
    return {
        "resolutions": [
            "512x512", "768x768", "1024x1024", 
            "512x768", "768x512", "1024x768", "768x1024"
        ],
        "recommended": "1024x1024"
    }

@app.get('/health')
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "service": "stable_diffusion_mcp",
        "gpu_available": torch.cuda.is_available(),
        "pipeline_loaded": pipeline is not None
    }
